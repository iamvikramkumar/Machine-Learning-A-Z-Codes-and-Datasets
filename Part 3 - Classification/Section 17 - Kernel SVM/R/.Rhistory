cor(d1$Profit,d1$RD_Spend)
cor(d1$Profit,d1$Administration)
cor(d1$Profit,d1$Marketing_spend)
d1$x1=d1$RD_Spend^2
d1$x2=d1$RD_Spend^3
d1$x3=d1$RD_Spend^4
library(caTools)
split=sample.split(d1$Profit,SplitRatio = 0.75)
train1=subset(d1,split==T)
test1=subset(d1,split==F)
train1[-4]=scale(train1[-4])
test[-4]=scale(test[-4])
test1[-4]=scale(test1[-4])
regressor=lm(formula=Profit~RD_Spend+x1+x2+x3,
data=train1)
y1=predict(regressor,test1[c(1,5,6,7)])
summary(regressor)
library(ModelMetrics)
rmse(y1,test1$Profit)
d2=data.frame("RD_Spend"=150000,"x1"=150000^2,
"x2"=150000^3,"x3"=150000^4)
y2=predict(regressor,d2)
y2
d1=read.csv(file.choose())
View(d1)
table(d1$loan_status)
sum(is.na(d1))
table(d1$loan_status)
class(d1$loan_status)
#Encode the dependent variable to make it factor
d1$loan_status=factor(d1$loan_status,
levels=c(" Approved","Rejected"),
labels=c(1,0))
class(d1$loan_status)
d1
#Encode the dependent variable to make it factor
d1$loan_status=factor(d1$loan_status,
levels=c(" Approved"," Rejected"),
labels=c(1,0))
d1
#Encode the dependent variable to make it factor
d1$loan_status=factor(d1$loan_status,
levels=c(" Approved","Rejected"),
labels=c(1,0))
d1
#Encode the dependent variable to make it factor
d1$loan_status=factor(d1$loan_status,
levels=c("Approved","Rejected"),
labels=c(1,0))
d1=read.csv(file.choose())
table(d1$loan_status)
sum(is.na(d1))
head(d1$loan_status)
#Encode the dependent variable to make it factor
d1$loan_status=factor(d1$loan_status,
levels=c(" Approved"," Rejected"),
labels=c(1,0))
sum(is.na(d1))
head(d1$loan_status)
colnames(d1)
d1=d1[c("loan_status","income_annum",
"loan_amount","loan_term","cibil_score")]
sum(is.na(d1))
#Splitting dataset
library(caTools)
split=sample.split(d1$loan_status,SplitRatio = 0.75)
train=subset(d1,split==TRUE)
test=subset(d1,split==FALSE)
1067+3202
View(d1)
#scaling independent variables
train[-1]=scale(train[-1])
test[-1]=scale(test[-1])
#Model Building--
library(class)
classifier1=knn(train=train,test=test,k=9,cl=train$loan_status)
library(e1071)
classifier2=naiveBayes(train[-1],train$loan_status)
library(rpart)
classifier3=rpart(formula=loan_status~.,data=train)
library(randomForest)
#ensemble algorithm-combining multiple algorithms-
#Random forest is combination of multiple decision trees
classifier4=randomForest(x=train[-1],y=train$loan_status,
ntrees=100)
d1=read.csv(file.choose())
View(d1)
table(d1$loan_status)
sum(is.na(d1))
class(d1$loan_status)
head(d1$loan_status)
#Encode the dependent variable to make it factor
d1$loan_status=factor(d1$loan_status,
levels=c(" Approved"," Rejected"),
labels=c(1,0))
#Model Building--knn, naive bayes, decision tree
library(class)
classifier1=knn(train=train,test=test,k=9,cl=train$loan_status)
library(caret)
confusionMatrix(classifier1,test$loan_status)
library(e1071)
classifier2=naiveBayes(x=train[-1],y=train$loan_status)
y2=predict(classifier2,test[-1])
library(caret)
confusionMatrix(classifier2,test$loan_status)
confusionMatrix(y2,test$loan_status)
library(rpart)
classifier3=rpart(formula=loan_status~.,data=train)
library(randomForest)
#ensemble algorithm-combining multiple algorithms-
#Random forest is combination of multiple decision trees
classifier4=randomForest(x=train[-1],y=train$loan_status,
ntrees=100)
library(caret)
y3=predict(classifier4,test[-1])
confusionMatrix(y3,test$loan_status)
d1=read.csv(file.choose())
View(d1)
#checking dependent variable for classes
table(d1$Profit)
#checking missing values
sum(is.na(d1))
#Eliminating unnecessary columns
d1=d1[-4]
colnames(d1)[1]="RD_Spend"
colnames(d1)[3]="MarketingSpend"
#Splitting dataset
library(caTools)
split=sample.split(d1$Profit,SplitRatio = 0.8)
training=subset(d1,split==TRUE)
testing=subset(d1,split==FALSE)
#Implement Multiple Linear Regression
regressor=lm(formula=Profit~.,data=training)
#Implement Multiple Linear Regression
regressor=lm(formula=Profit~.,data=training)
summary(regressor)
library(ModelMetrics)
#Implement Multiple Linear Regression
regressor1=lm(formula=Profit~.,data=training)
summary(regressor1)
#Implement Multiple Linear Regression
regressor1=lm(formula=Profit~.,data=training)
summary(regressor1)
ypred1=predict(regressor1,testing[-4])
library(ModelMetrics)
rmse(ypred1,testing[4])
rmse(ypred1,testing$Profit)
d1$x2=d1$RD_Spend^2
d1$x3=d1$RD_Spend^3
d1$x4=d1$RD_Spend^4
#implementing Polynomial Regression
regressor2=lm(formula=Profit~RD_Spend+x2+x3+x4,
data=training[c(-2,-3)])
d1=d1[c(-2,-3)]
library(caTools)
split=sample.split(d1$Profit,SplitRatio = 0.8)
training2=subset(d1,split==TRUE)
testing2=subset(d1,split==FALSE)
#implementing Polynomial Regression
regressor2=lm(formula=Profit~.,
data=training2)
ypred2=predict(regressor2,testing2[-2])
summary(regressor2)
library(ModelMetrics)
rmse(ypred2,testing2$Profit)
d1=read.csv(file.choose())
View(d1)
colnames(d1)
d1=d1[c("Attrition","MonthlyIncome","MonthlyRate","HourlyRate")]
lapply(d1,summary)
sum(is.na(d1))
#scaling
d1[-1]=scale(d1[-1])
class(d1$Attrition)
d1$Attrition=factor(d1$Attrition,
levels=c("Yes","No"),
labels=c(1,0))
class(d1$Attrition)
#splitting dataset
library(caTools)
t1=sample.split(d1$Attrition,SplitRatio = 0.75)
train1=subset(d1,t1==TRUE)
test1=subset(d1,t1==FALSE)
#Model1-KNN
library(class)
cl1=knn(train1[-1],test1[-1],k=9,cl=train1$Attrition)
cl1=knn(train1,test1[-1],k=9,cl=train1$Attrition)
cl1=knn(train1[-1],test1[-1],k=9,cl=train1$Attrition)
library(caret)
confusionMatrix(cl1,test$Attrition)
confusionMatrix(cl1,test1$Attrition)
cl1=knn(train1[-1],test1[-1],k=12,cl=train1$Attrition)
library(caret)
confusionMatrix(cl1,test1$Attrition)
cl1=knn(train1[-1],test1[-1],k=21,cl=train1$Attrition)
library(caret)
confusionMatrix(cl1,test1$Attrition)
cl1=knn(train1[-1],test1[-1],k=90,cl=train1$Attrition)
library(caret)
confusionMatrix(cl1,test1$Attrition)
cl1=knn(train1[-1],test1[-1],k=22,cl=train1$Attrition)
library(caret)
confusionMatrix(cl1,test1$Attrition)
#Model2--Naive bayes
library(e1071)
cl2=naiveBayes(x=train1[-1],y=train1[1])
y1=predict(cl2,test1[-1])
library(caret)
confusionMatrix(y1,test1$Attrition)
#Model3--decision tree
library(rpart)
cl3=rpart(formula=Attrition~.,data=train1,
method='class')
y2=predict(cl3,test1$Attrition)
y2=predict(cl3,test1[-1])
confusionMatrix(y2,test1$Attrition)
confusionMatrix(y2,test1$Attrition,type='class')
y2=predict(cl3,test1[-1],type='class')
confusionMatrix(y2,test1$Attrition)
cl4=randomForest(formula=Attrition~.,data=train1)
#Model4--Random Forest
library(randomForest)
cl4=randomForest(formula=Attrition~.,data=train1)
y2=predict(cl3,test1[-1],type='class')
y2=predict(cl4,test1[-1],type='class')
y3=predict(cl4,test1[-1],type='class')
confusionMatrix(y3,test1$Attrition)
d1=read.csv(file.choose())
View(d1)
#Eliminating unnecessary columns
d1=d1[c("income_annum","loan_amount","loan_term","cibil_score")]
#renaming columns
colnames(d1)
#renaming columns
colnames(d1)[1]="annual_income"
colnames(d1)
#checking the missing values
sum(is.na(d1))
cor(d1$loan_amount,d1$annual_income)
cor(d1$loan_amount,d1$loan_term)
cor(d1$loan_amount,d1$cibil_score)
#splitting dataset
library(caTools)
t1=sample.split(d1$loan_amount,SplitRatio = 0.75)
train3=subset(d1,t1==TRUE)
test3=susbet(d1,t1==FALSE)
test3=subset(d1,t1==FALSE)
d1=d1[-3]
test3[-2]=scale(test3[-2])
#scaling
train3[-2]=scale(train3[-2])
#Multiple Linear regression
r1=lm(formula=loan_amount~.,data=train3)
y1=predict(r1,test[-2])
y1=predict(r1,test3[-2])
library(ModelMetrics)
rmse(y1,test3$loan_amount)
d2=data.frame("annual_income"=960000,"cibil_score"=875)
y1=predict(r1,d2)
y2=predict(r1,d2)
View(d1)
d1=read.csv(file.choose())
#Eliminating unnecessary columns
d1=d1[c("income_annum","loan_amount","loan_term","cibil_score")]
#renaming columns
colnames(d1)[1]="annual_income"
#checking the missing values
sum(is.na(d1))
cor(d1$loan_amount,d1$annual_income)
cor(d1$loan_amount,d1$loan_term)
cor(d1$loan_amount,d1$cibil_score)
d1=d1[-3]
#splitting dataset
library(caTools)
t1=sample.split(d1$loan_amount,SplitRatio = 0.75)
train3=subset(d1,t1==TRUE)
test3=subset(d1,t1==FALSE)
#scaling
train3[-2]=scale(train3[-2])
test3[-2]=scale(test3[-2])
#Multiple Linear regression
r1=lm(formula=loan_amount~.,data=train3)
y1=predict(r1,test3[-2])
library(ModelMetrics)
rmse(y1,test3$loan_amount)
d2=data.frame("annual_income"=960000,
"cibil_score"=875)
y2=predict(r1,d2)
y2
#polynomial regression
d1$x2=d1$annual_income^2
d1$x3=d1$annual_income^3
cor(d1$loan_amount,d1$x2)
cor(d1$loan_amount,d1$x3)
#scaling again
d1[-2]=scale(d1[-2])
#splitting dataset again
library(caTools)
t2=sample.split(d1$loan_amount,SplitRatio = 0.75)
train4=subset(d1,t2==T)
test4=subset(d1,t2==F)
View(test4)
r2=lm(formula=loan_amount~annual_income+x2+x3,data=train3)
r2=lm(formula=loan_amount~annual_income+x2+x3,data=train4)
y2=predict(r1,test4[c(-2,-3)])
y2=predict(r2,test4[c(-2,-3)])
library(ModelMetrics)
rmse(y2,test4$loan_amount)
d2=data.frame("annual_income"=960000,
"x2"=960000^2,"x3"=960000^3)
y3=predict(r2,d2)
y2
y3
d1=read.csv(file.choose())
View(d1)
d1=d1[-1]
sum(is.na(d1))
class(d1$diagnosis_result)
d1$diagnosis_result=factor(d1$diagnosis_result,
levels=c("B","M"),
labels=c(1,0))
class(d1$diagnosis_result)
#scaling
d1[-1]=scale(d1[-1])
#splitting dataset
library(caTools)
s1=sample.split(d1$diagnosis_result,SplitRatio = 0.75)
t1=subset(d1,s1==T)
t2=subset(d1,s1==F)
#model1-knn
library(class)
classifier1=knn(t1,t2,k=7,cl=t1$diagnosis_result)
#model2--naive bayes
library(e1071)
classifier2=naiveBayes(x=t1[-1],y=t1$diagnosis_result)
y2=predict(classifier2,t2[-1])
library(caret)
confusionMatrix(t2$diagnosis_result,y2)
confusionMatrix(classifier1,t2$diagnosis_result)
#model3-Decision Tree
library(rpart)
classifier3=rpart(formula=diagnosis_result,
data=t1)
classifier3=rpart(formula=diagnosis_result~.,
data=t1)
y3=predict(classifier3,t2[-1])
library(caret)
confusionMatrix(y3,t1$diagnosis_result)
confusionMatrix(y3,t2$diagnosis_result)
confusionMatrix(t2$diagnosis_result,y3)
y3
y3=predict(classifier3,t2[-1],type'class')
y3=predict(classifier3,t2[-1],type='class')
library(caret)
confusionMatrix(t2$diagnosis_result,y3)
d1=read.csv(file.choose())
View(d1)
table(d1$depression_severity)
sum(is.na(d1))
missing=d1[!complete.cases(d1),]
missing
missing=d1[!complete.cases(d1),8]
missing
sum(is.na(d1$depression_severity))
d1$depression_severity=na.omit(d1$depression_severity)
na.omit(d1$depression_severity)
d1$depression_severity=na.omit(d1$depression_severity)
d1=read.csv(file.choose())
View(d1)
d1=read.csv(file.choose())
table(d1$depression_severity)
sum(is.na(d1))
sum(is.na(d1$depression_severity))
d1=d1[complete.cases(d1[1])]
d1=d1[complete.cases(d1[1]),]
View(d1)
sum(is.na(d1$depression_severity))
lapply(d1,summary)
d1=read.csv(file.choose())
View(d1)
lapply(d1,summary)
d1=d1[c("age","bmi","phq_score","gad_score","epworth_score","depression_severity")]
d1=d1[complete.cases(d1[6]),]
sum(is.na(d1$depression_severity))
#Load the dataset
d1=read.csv(file.choose())
View(d1)
#Choose the dependent and independent variables
#depression_severity--dependent variable
d1=d1[c("age","bmi","phq_score","gad_score",
"epworth_score","depression_severity")]
lapply(d1,summary)
table(d1$depression_severity)
sum(is.na(d1$depression_severity))
d1=d1[complete.cases(d1[6],)]
d1=d1[complete.cases(d1[6]),]
sum(is.na(d1$depression_severity))
lapply(d1,summary)
d1$epworth_score=ifelse(is.na(d1$epworth_score),
mean(d1$epworth_score,na.rm=T),
d1$epworth_score)
table(d1$depression_severity)
lapply(d1,summary)
class(d1$depression_severity)
table(d1$depression_severity)
head(d1$depression_severity)
table(d1$depression_severity)
d1$depression_severity=factor(d1$depression_severity,
levels=c("none","None-minimal","Mild",
"Moderate","Moderately severe",
"Severe"),
labels=c(0,1,2,3,4,5))
class(d1$depression_severity)
#no scaling bcz values range between 0 to 52 in independent columns
#splitting dataset
library(caTools)
split=sample.split(d1$depression_severity,SplitRatio = 0.75)
train=subset(d1,split==T)
test=subset(d1,split==F)
#Model1--knn
library(class)
classifier1=knn(train,test,cl=train$depression_severity,k=9)
library(caret)
confusionMatrix(classifier1,test$depression_severity)
#accuracy==90.21%
#Model2--Naive Bayes
library(e1071)
classifier2=naiveBayes(x=train[-6],y=train$depression_severity)
y2=predict(classifier2,test[-6])
library(caret)
confusionMatrix(classifier2,test$depression_severity)
confusionMatrix(y2,test$depression_severity)
#accuracy=96.39
#model3--decision tree
library(rpart)
classifier3=rpart(formula=depression_severity~.,data=train)
y3=predict(classifier3,test[-6])
confusionMatrix(y3,test$depression_severity)
confusionMatrix(y3,test$depression_severity,type='class')
y3=predict(classifier3,test[-6],type='class')
confusionMatrix(y3,test$depression_severity)
#Accuracy=100%
d2=data.frame("age"=18,"bmi"=22.10029,"phq_score"=7,"gad_score"=12,"epworth_score"=9)
y0=predict(classifier3,d2,type='class')
y0
#model4--RandomForest
library(randomForest)
classifier4=randomForest(formula=depression_severity~.,data=train,ntrees=50)
y3=predict(classifier3,test[-6],type='class')
confusionMatrix(y3,test$depression_severity)
setwd("C:/1_Study material/Machine Learning using R/Machine Learning A-Z (Codes and Datasets)/Part 3 - Classification/Section 17 - Kernel SVM/R")
d1=read.csv(file.choose())
View(d1)
d1=d1[3:5]
#or d1=d1[c(-1,-2)]
#or d1=d1[c(3,4,5)]
#checking for missing values
sum(is.na(d1))
#check if dependent variable is categorical or not
table(d1$Purchased)
##Classification model need to  be built
class(d1$Purchased)
#Encode the Dependent variable into factor
d1$Purchased=factor(d1$Purchased,levels=c(0,1))
class(d1$Purchased)
#scaling-- standarization or normalization
d1[-3]=scale(d1[-3])
#Model building
#split dataset
library(caTools)
split=sample.split(d1$Purchased,SplitRatio = 0.75)
t1=subset(d1,split==T)
t2=subset(d1,split==F)
#KNN
library(class)
c1=knn(t1,t2,k=30,cl=train$Purchased)
c1=knn(t1,t2,k=30,cl=t1$Purchased)
library(caret)
confusionMatrix(c1,t2$Purchased)
c1=knn(t1,t2,k=31,cl=t1$Purchased)
library(caret)
confusionMatrix(c1,t2$Purchased)
c1=knn(t1,t2,k=32,cl=t1$Purchased)
library(caret)
confusionMatrix(c1,t2$Purchased)
c1=knn(t1,t2,k=33,cl=t1$Purchased)
library(caret)
confusionMatrix(c1,t2$Purchased)
c1=knn(t1,t2,k=34,cl=t1$Purchased)
library(caret)
confusionMatrix(c1,t2$Purchased)
c1=knn(t1,t2,k=35,cl=t1$Purchased)
library(caret)
confusionMatrix(c1,t2$Purchased)
c1=knn(t1,t2,k=36,cl=t1$Purchased)
library(caret)
confusionMatrix(c1,t2$Purchased)
d2=data.frame("Age"=-0.9210258, "EstimatedSalary"=0.50613016)
y1=predict(c1,d2)
y1=knn(t1,d2,k=10,cl=t1$Purchased)
#Naive Bayes
library(e1071)
c2=naiveBayes(x=t1[-3],y=t1[3])
y2=predict(c2,t2[-3])
library(caret)
confusionMatrix(y2,t2$Purchased)
#SVM
library(e1071)
c3=svm(formula=Purchased~.,data=t1)
y3=predict(c3,t2[-3])
library(caret)
confusionMatrix(y3,t2$Purchased)
